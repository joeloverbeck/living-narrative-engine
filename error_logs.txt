 [22:26:10.007] ğŸ”„ DEBUG LlmRequestService: LlmRequestService: Initiating call via RetryManager to https://openrouter.ai/api/v1/chat/completions for llmId 'claude-sonnet-4.5'.
[1]                     â†³ Context: {
[1]                       "llmId": "claude-sonnet-4.5"
[1]                     }
[1] [22:26:10.007] ğŸŒ INFO HttpAgentService: HttpAgentService: Created new agent for https://openrouter.ai:443
[1] [22:26:10.007] ğŸ”„ DEBUG HttpAgentService: HttpAgentService: Reusing agent for https://openrouter.ai:443 (1 requests)
[1] [22:26:10.007] ğŸ”„ DEBUG LlmRequestService: LlmRequestService: Using HTTP agent with connection pooling for llmId 'claude-sonnet-4.5' to https://openrouter.ai/api/v1/chat/completions.
[1] [22:26:10.008] ğŸ”„ DEBUG RetryManager: RetryManager: Initiating request sequence for https://openrouter.ai/api/v1/chat/completions with maxRetries=3, baseDelayMs=1000, maxDelayMs=10000.
[1] [22:26:10.008] ğŸ”„ DEBUG System: Attempt 1/3 - Fetching POST https://openrouter.ai/api/v1/chat/completions
[1] [22:26:13.018] ğŸ”„ DEBUG RetryManager: RetryManager: Attempt 1/3 for https://openrouter.ai/api/v1/chat/completions - Request successful (status 200). Parsing JSON response.
[1] [22:27:46.692] ğŸŒ INFO RetryManager: RetryManager: Successfully fetched and parsed JSON from https://openrouter.ai/api/v1/chat/completions after 1 attempt(s).
[1] [22:27:46.692] ğŸ”„ INFO LlmRequestService: LlmRequestService: Successfully received response from LLM provider for llmId 'claude-sonnet-4.5'. Status: 200 (assumed for RetryManager success).
[1]                     â†³ Context: {
[1]                       "llmId": "claude-sonnet-4.5"
[1]                     }
[1] [22:27:46.693] ğŸ“ DEBUG System:    LLM Provider Response Body (Preview for 'claude-sonnet-4.5'): {"id":"gen-1759695970-RduEpxItvA6udUPsthKz","provider":"Google","model":"anthropic/claude-sonnet-4.5...
[1]                     â†³ Context: {
[1]                       "llmId": "claude-sonnet-4.5"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG LlmRequestController: LlmRequestController: LlmRequestService returned success for llmId 'claude-sonnet-4.5'. Relaying to client with status 200.
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "llmId": "claude-sonnet-4.5"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG System: Request a798bd82-5392-4004-a312-f75e64ac9693: State processing â†’ responding
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "source": "success"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG System: Request a798bd82-5392-4004-a312-f75e64ac9693: Response committed to 'success'
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "source": "success"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG System: LLM request metrics recorded
[1]                     â†³ Context: {
[1]                       "provider": "unknown",
[1]                       "model": "claude-sonnet-4.5",
[1]                       "status": "success",
[1]                       "duration": 96.690200734,
[1]                       "tokens": "[MASKED]"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG System: Request a798bd82-5392-4004-a312-f75e64ac9693: State responding â†’ completed
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "method": "json"
[1]                     }
[1] [22:27:46.693] ğŸ”„ DEBUG System: Request a798bd82-5392-4004-a312-f75e64ac9693: State completed â†’ completed
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "method": "send"
[1]                     }
[1] [22:27:46.694] ğŸ”„ DEBUG System: HTTP request metrics recorded
[1]                     â†³ Context: {
[1]                       "method": "POST",
[1]                       "route": "/api/llm-request",
[1]                       "statusCode": 200,
[1]                       "duration": 96.734412534,
[1]                       "requestSize": 33370,
[1]                       "responseSize": 588
[1]                     }
[1] [22:27:46.694] ğŸ”„ DEBUG System: Request a798bd82-5392-4004-a312-f75e64ac9693: State completed â†’ completed
[1]                     â†³ Context: {
[1]                       "requestId": "a798bd82-5392-4004-a312-f75e64ac9693",
[1]                       "method": "end"
[1]                     }
[1] [22:30:51.499] ğŸŒ DEBUG HttpAgentService: HttpAgentService: Adaptive cleanup interval adjusted to 585000ms (low-load+few-agents)
[1]                     â†³ Context: {
[1]                       "requestRate": 0,
[1]                       "memoryUsageMB": 0.0009765625,
[1]                       "agentCount": 1,
[1]                       "intervalMultiplier": 1.9500000000000002
[1]                     }
[1] [22:30:51.499] ğŸŒ DEBUG HttpAgentService: HttpAgentService: Scheduled next cleanup in 585000ms