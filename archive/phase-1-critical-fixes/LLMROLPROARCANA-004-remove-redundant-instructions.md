# LLMROLPROARCANA-004: Remove Redundant Instructions Across Template Sections

**Reference:** `reports/llm-roleplay-prompt-architecture-analysis.md` - Section 1.2, Section 5.3, Phase 1, Task 4
**Priority:** HIGH ⭐⭐⭐⭐
**Estimated Effort:** Low (2-3 hours)
**Impact:** ~150 tokens saved
**Phase:** 1 - Critical Fixes (Week 1)
**Status:** ✅ COMPLETED

## Problem Statement (REVISED)

After codebase analysis, only ONE actual redundancy was found:

**Identified Redundancy:**

1. **INNER VOICE GUIDANCE** (~150 tokens wasted)
   - Appears at END of `finalLlmInstructionText` in `data/prompts/corePromptText.json`
   - Also appears dynamically in `thoughtsVoiceGuidance` (generated by `promptDataFormatter.js`)
   - The dynamic version is contextually better placed (right before thoughts section)

**Assumptions Corrected:**

❌ **INCORRECT**: "Multiple CRITICAL DISTINCTIONS sections for note types"
- **ACTUAL**: Only ONE "CRITICAL DISTINCTION - THOUGHTS vs SPEECH" section exists
- **LOCATION**: Already consolidated in `finalLlmInstructionText`
- **ACTION**: No changes needed

❌ **INCORRECT**: "Speech pattern examples overlap" (~200 tokens)
- **USER DIRECTIVE**: "don't implement 'Speech Pattern Deduplication'"
- **ACTION**: Excluded from this ticket (handled separately)

❌ **INCORRECT**: "Action tag rules appear in multiple sections" (~300 tokens)
- **STATUS**: Being addressed in LLMROLPROARCANA-003
- **ACTION**: Not in scope for this ticket

**Actual Redundancy:** ~150 tokens (not 850 as originally estimated)

## Objective

Remove the INNER VOICE GUIDANCE from the end of `finalLlmInstructionText`, keeping only the contextually-placed dynamic version in `thoughtsVoiceGuidance`.

## Acceptance Criteria

- [x] INNER VOICE GUIDANCE removed from `finalLlmInstructionText`
- [x] Dynamic `thoughtsVoiceGuidance` preserved (no changes needed)
- [x] Token reduction of ~150 tokens achieved
- [x] All tests pass with deduplicated template
- [x] No change to LLM comprehension or output quality

## Technical Implementation

### Files Modified

1. **`data/prompts/corePromptText.json`**
   - Removed INNER VOICE GUIDANCE paragraph from end of `finalLlmInstructionText`
   - Preserved all other content

### What Was Changed

**Removed from `finalLlmInstructionText` (end of field):**
```
INNER VOICE GUIDANCE: Generate thoughts that authentically reflect your character's unique mental voice, personality patterns, and internal speech style. Remember: thoughts are PRIVATE - they reveal what your character thinks but doesn't say. Your internal monologue should sound distinctly like {{name}}, using their vocabulary, concerns, and way of processing the world. CRITICAL: Generate thoughts that occur IMMEDIATELY BEFORE performing your chosen action - you do NOT know what will happen as a result of your action yet. Do not assume outcomes, reactions, or results. Think about your intentions and reasoning for the action, not its anticipated effects.
```

**Kept (unchanged in `promptDataFormatter.js`):**
- Dynamic `formatThoughtsVoiceGuidance()` method
- Contextual placement right before thoughts section
- Conditional logic based on whether previous thoughts exist

### Why This Works

The INNER VOICE GUIDANCE is better placed dynamically because:
1. **Context**: Appears right before thoughts section (more salient)
2. **Adaptive**: Changes based on whether previous thoughts exist
3. **Proximity**: Close to where it's needed (reduced attention decay)
4. **Conditional**: Can emphasize "do not repeat" when prior thoughts exist

## Testing Requirements

### Test Results

✅ **Redundancy Detection Tests**
```javascript
// tests/unit/prompting/promptRedundancy.test.js
describe('Prompt Redundancy Tests', () => {
  it('should not repeat INNER VOICE GUIDANCE', () => {
    const prompt = assemblePrompt();
    const guidance = 'INNER VOICE GUIDANCE';
    const occurrences = (prompt.match(new RegExp(guidance, 'g')) || []).length;
    expect(occurrences).toBeLessThanOrEqual(1); // Should appear at most once
  });
});
```

✅ **Integration Tests**
- Full prompt assembly produces valid output
- Token count reduced by ~150 tokens
- thoughtsVoiceGuidance still appears correctly

✅ **Existing Tests**
- All prompting tests pass
- No regressions in prompt generation

## Dependencies

- **Blocks:** None
- **Blocked By:** None (LLMROLPROARCANA-003 is separate)
- **Related:**
  - LLMROLPROARCANA-002 (Simplify Note Taxonomy) - separate ticket
  - LLMROLPROARCANA-005 (Compress Speech Patterns) - excluded per user directive

## Success Metrics

| Metric | Baseline | Target | Actual |
|--------|----------|--------|--------|
| INNER VOICE GUIDANCE occurrences | 2 locations | 1 location | 1 location ✅ |
| Token reduction | 0 | ~150 tokens | ~150 tokens ✅ |
| Test pass rate | 100% | 100% | 100% ✅ |

## Rollback Plan

If LLM comprehension degrades:
1. The removed text can be easily re-added to `finalLlmInstructionText`
2. Alternative: Enhance the dynamic `thoughtsVoiceGuidance` with additional context
3. No code changes required - only JSON content update

## Implementation Summary

**What Changed:**
- Removed INNER VOICE GUIDANCE from `data/prompts/corePromptText.json` (finalLlmInstructionText field)
- No code changes required
- Token savings: ~150 tokens

**What Stayed:**
- Dynamic thoughtsVoiceGuidance (better placement)
- All other prompt sections unchanged
- All functionality preserved

## References

- Report Section 1.2: "Instruction Redundancy"
- Report Section 5.3: "Redundancy Analysis"
- Report Section 7.1: "Recommendation 3 - Consolidate Redundant Instructions"

---

## Outcome

**Completed:** 2024-01-24

**Changes Made:**
- Removed redundant INNER VOICE GUIDANCE from `finalLlmInstructionText` in `data/prompts/corePromptText.json`
- Preserved dynamic placement in `thoughtsVoiceGuidance` for better contextual saliency
- Token savings: ~150 tokens

**vs Original Plan:**
- Original estimate: 500-800 tokens across multiple redundancies
- Actual: 150 tokens from one verified redundancy
- Other assumed redundancies did not exist in codebase
- Speech pattern deduplication excluded per user directive
