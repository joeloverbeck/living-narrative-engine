/**
 * @file FullTurnExecution.e2e.test.js
 * @description E2E test suite for complete AI turn execution using Test Module Pattern
 *
 * This test suite covers the complete AI turn execution flow as specified
 * in section 6 of the LLM prompt workflow analysis report. It tests the
 * integration of all AI subsystems from decision request through action
 * execution and state updates.
 *
 * MIGRATION NOTE: This file has been migrated to use the Test Module Pattern,
 * achieving 80%+ reduction in test setup complexity compared to direct facade usage.
 * - BEFORE: 150+ lines manual setup â†’ 20 lines facade setup
 * - AFTER: 20 lines facade setup â†’ 5 lines Test Module Pattern
 *
 * Test Coverage:
 * - Complete AI turn execution from decision to action
 * - LLM configuration switching (tool calling vs JSON schema)
 * - Error handling during turn execution
 * - Performance validation
 * - Integration between all AI subsystems
 */

import {
  describe,
  beforeEach,
  afterEach,
  test,
  expect,
  jest,
} from '@jest/globals';
import { TestModuleBuilder } from '../../common/testing/builders/testModuleBuilder.js';

/**
 * E2E test suite for complete AI turn execution using Test Module Pattern
 *
 * Tests the complete flow from LLM decision request through action execution
 * as outlined in the report section "6. Full Turn Execution Test"
 *
 * TEST MODULE PATTERN: Simplified from 20 lines facade setup to 5 lines fluent API
 */
describe('E2E: Complete AI Turn Execution', () => {
  let testEnv;

  beforeEach(async () => {
    // BEFORE (facade pattern): 20 lines of setup with facades + initialization
    // AFTER (test module pattern): 5 lines with fluent API
    testEnv = await TestModuleBuilder.forTurnExecution()
      .withMockLLM({ strategy: 'tool-calling' })
      .withTestActors([{ id: 'ai-actor', name: 'Elara the Bard' }])
      .withWorld({ name: 'Test World', createConnections: true })
      .build();
  });

  afterEach(async () => {
    // Simple cleanup method provided by test module
    await testEnv.cleanup();
  });

  /**
   * Test: Complete AI turn execution flow - Success Path
   *
   * This is the core test from the report recommendation that validates
   * the complete flow from AI decision to action execution.
   *
   * TEST MODULE PATTERN: Mock configuration integrated into module setup
   */
  test('should execute full AI turn from decision to action', async () => {
    // Setup: Configure mock AI decision
    const expectedDecision = {
      actionId: 'core:move', // Move action
      targets: { direction: 'north' },
      reasoning:
        "I think I'll explore the market and see what stories await there!",
      speech:
        "I think I'll explore the market and see what stories await there!",
      thoughts:
        'The market sounds bustling and full of potential for new tales.',
      notes: [
        {
          text: 'Market Square seems like a good place to find stories',
          subject: 'Market Square',
          context: 'planning next move',
          tags: ['location', 'opportunity'],
        },
      ],
    };

    // Configure test module mocks - cleaner API than facade mocking
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: expectedDecision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:move', name: 'Move', available: true },
          { actionId: 'core:look', name: 'Look Around', available: true },
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:move']: {
          success: true,
          validatedAction: {
            actionId: 'core:move',
            actorId: 'ai-actor',
            targets: { direction: 'north' },
          },
        },
      },
    });

    // Execute: Use convenient test module method
    const turnResult = await testEnv.executeAITurn('ai-actor');

    // Assert: Verify execution results
    expect(turnResult.success).toBe(true);
    expect(turnResult.actorId).toBe('ai-actor');
    expect(turnResult.aiDecision).toMatchObject({
      actionId: expectedDecision.actionId,
      targets: expectedDecision.targets,
      reasoning: expectedDecision.reasoning,
    });
    expect(turnResult.validation.success).toBe(true);
    expect(turnResult.availableActionCount).toBe(3);
    expect(turnResult.duration).toBeGreaterThanOrEqual(0);

    // Verify the chosen action is valid
    expect(turnResult.aiDecision.actionId).toBe('core:move');
    expect(turnResult.aiDecision.targets).toEqual({ direction: 'north' });

    // Verify validation passed
    expect(turnResult.validation.validatedAction.actionId).toBe('core:move');
    expect(turnResult.validation.validatedAction.actorId).toBe('ai-actor');

    // Verify performance
    expect(turnResult.duration).toBeLessThan(1000); // 1 second max for mocked execution

    // Verify events were dispatched
    const events = testEnv.facades.turnExecutionFacade.getDispatchedEvents();
    expect(Array.isArray(events)).toBe(true);
  });

  /**
   * Test: LLM Configuration Switching
   *
   * Validates that the system can switch between different LLM configurations
   * (tool calling vs JSON schema) as mentioned in the report.
   *
   * TEST MODULE PATTERN: Strategy switching through module reconfiguration
   */
  test('should handle LLM configuration switching between strategies', async () => {
    // Test Tool Calling Strategy First
    const toolCallingDecision = {
      actionId: 'core:wait',
      targets: {},
      speech: "I'll wait and observe for now.",
      thoughts: 'Better to take in my surroundings first.',
    };

    // Configure mocks for tool calling
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: toolCallingDecision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:wait']: {
          success: true,
          validatedAction: {
            actionId: 'core:wait',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    const turnResult1 = await testEnv.executeAITurn('ai-actor');
    expect(turnResult1.success).toBe(true);
    expect(turnResult1.aiDecision.actionId).toBe('core:wait');

    // Create new test environment with json-schema strategy
    const jsonSchemaTestEnv = await TestModuleBuilder.forTurnExecution()
      .withMockLLM({ strategy: 'json-schema' })
      .withTestActors([{ id: 'ai-actor', name: 'Elara the Bard' }])
      .withWorld({ name: 'Test World' })
      .build();

    // Test different decision with new strategy
    const jsonSchemaDecision = {
      actionId: 'core:look',
      targets: {},
      speech: 'Let me say hello to everyone!',
      thoughts: 'A friendly greeting would be nice.',
    };

    jsonSchemaTestEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: jsonSchemaDecision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:look', name: 'Look Around', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:look']: {
          success: true,
          validatedAction: {
            actionId: 'core:look',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    const turnResult2 = await jsonSchemaTestEnv.executeAITurn('ai-actor');
    expect(turnResult2.success).toBe(true);
    expect(turnResult2.aiDecision.actionId).toBe('core:look');

    // Verify both strategies worked correctly
    expect(turnResult1.aiDecision.actionId).not.toBe(
      turnResult2.aiDecision.actionId
    );

    // Cleanup second environment
    await jsonSchemaTestEnv.cleanup();
  });

  /**
   * Test: Error Handling During Turn Execution
   *
   * Validates error handling scenarios as mentioned in the report
   * for network errors, invalid JSON, and other failure modes.
   */
  test('should handle LLM errors gracefully during turn execution', async () => {
    // Test Action Discovery Failure - No available actions
    testEnv.facades.turnExecutionFacade.setupMocks({
      actionResults: {
        ['ai-actor']: [], // No actions available
      },
    });

    const noActionsResult = await testEnv.executeAITurn('ai-actor');
    expect(noActionsResult.success).toBe(false);
    expect(noActionsResult.error).toContain('No available actions');

    // Test AI Decision Failure - Invalid decision
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: {
          // Missing required actionId field
          targets: {},
          speech: 'Invalid decision without action',
        },
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
    });

    const invalidDecisionResult = await testEnv.executeAITurn('ai-actor');
    expect(invalidDecisionResult.success).toBe(false);
    expect(invalidDecisionResult.error).toContain(
      'did not specify a valid action'
    );

    // Test Action Validation Failure
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: {
          actionId: 'core:invalid-action',
          targets: {},
          speech: 'Attempting invalid action',
        },
      },
      actionResults: {
        ['ai-actor']: [
          {
            actionId: 'core:invalid-action',
            name: 'Invalid Action',
            available: true,
          },
        ],
      },
      validationResults: {
        ['ai-actor:core:invalid-action']: {
          success: false,
          error: 'Action not found',
          code: 'ACTION_NOT_FOUND',
        },
      },
    });

    const validationFailureResult = await testEnv.executeAITurn('ai-actor');
    expect(validationFailureResult.success).toBe(false);
    expect(validationFailureResult.error).toBe('Action validation failed');
    expect(validationFailureResult.validation.success).toBe(false);
  });

  /**
   * Test: Integration Validation
   *
   * Validates that all AI subsystems work together correctly
   * and that events flow properly through the system.
   */
  test('should properly integrate all AI subsystems', async () => {
    // Setup response with comprehensive data
    const comprehensiveDecision = {
      actionId: 'core:look', // Use a simple action that exists
      targets: {},
      speech: "ðŸŽµ Gather 'round, friends, for I have tales to tell! ðŸŽµ",
      thoughts:
        "A performance will lift everyone's spirits and might draw some interesting characters forward.",
      reasoning: 'I want to observe my surroundings and connect with others.',
      notes: [
        {
          text: 'The tavern crowd seems receptive to entertainment',
          subject: 'Tavern atmosphere',
          context: 'observing before performance',
          tags: ['social', 'opportunity'],
        },
        {
          text: 'Performance could attract potential story sources',
          subject: 'Strategic planning',
          context: 'turn planning',
          tags: ['strategy', 'stories'],
        },
      ],
    };

    // Configure test module mocks
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: comprehensiveDecision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:look', name: 'Look Around', available: true },
          { actionId: 'core:wait', name: 'Wait', available: true },
          { actionId: 'core:move', name: 'Move', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:look']: {
          success: true,
          validatedAction: {
            actionId: 'core:look',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    // Execute the turn
    const turnResult = await testEnv.executeAITurn('ai-actor');

    // Verify the turn executed successfully
    expect(turnResult.success).toBe(true);
    expect(turnResult.actorId).toBe('ai-actor');
    expect(turnResult.aiDecision).toMatchObject({
      actionId: comprehensiveDecision.actionId,
      targets: comprehensiveDecision.targets,
      speech: comprehensiveDecision.speech,
      thoughts: comprehensiveDecision.thoughts,
      reasoning: comprehensiveDecision.reasoning,
    });

    // Verify notes structure is preserved
    expect(Array.isArray(turnResult.aiDecision.notes)).toBe(true);
    expect(turnResult.aiDecision.notes).toHaveLength(2);

    turnResult.aiDecision.notes.forEach((note) => {
      expect(note).toHaveProperty('text');
      expect(note).toHaveProperty('subject');
      expect(note).toHaveProperty('context');
      expect(note).toHaveProperty('tags');
      expect(Array.isArray(note.tags)).toBe(true);
    });

    // Verify validation passed
    expect(turnResult.validation.success).toBe(true);
    expect(turnResult.validation.validatedAction.actionId).toBe('core:look');

    // Verify AI subsystems integration
    expect(turnResult.availableActionCount).toBe(3);
    expect(turnResult.duration).toBeGreaterThanOrEqual(0);
  });

  /**
   * Test: Token Estimation and Prompt Generation
   *
   * Validates that prompts are generated correctly and token estimation works
   * as mentioned in the report for token limit validation.
   */
  test('should generate valid prompts and estimate tokens correctly', async () => {
    // Setup for prompt generation test
    const decision = {
      actionId: 'core:wait',
      targets: {},
      speech: 'Let me take in my surroundings first.',
      thoughts: 'I should observe before acting.',
      reasoning: 'Patience and observation lead to wisdom.',
    };

    // Configure test module mocks
    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: decision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
          { actionId: 'core:look', name: 'Look Around', available: true },
          { actionId: 'core:move', name: 'Move', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:wait']: {
          success: true,
          validatedAction: {
            actionId: 'core:wait',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    // Execute turn - this will internally generate a prompt
    const turnResult = await testEnv.executeAITurn('ai-actor');

    // Verify the turn completed successfully
    expect(turnResult.success).toBe(true);
    expect(turnResult.aiDecision.actionId).toBe(decision.actionId);

    // The test module pattern handles prompt generation internally
    // We can verify that the AI decision was made correctly, which implies
    // the prompt was generated and processed successfully
    expect(turnResult.actorId).toBe('ai-actor');
    expect(turnResult.aiDecision.speech).toBe(decision.speech);
    expect(turnResult.aiDecision.thoughts).toBe(decision.thoughts);

    // Verify that prompt generation didn't exceed reasonable time
    expect(turnResult.duration).toBeGreaterThanOrEqual(0);
    expect(turnResult.duration).toBeLessThan(5000); // Should complete within 5 seconds

    // The new system uses templated prompts with proper sections
    // The test module ensures these are correctly formatted
    expect(turnResult.availableActionCount).toBe(3);
  });

  /**
   * Test: Graceful Operations Handling
   *
   * Validates that test module handles complex scenarios and operations gracefully
   * in various execution contexts.
   *
   * TEST MODULE PATTERN: Simplified error boundary and graceful handling testing
   */
  test('should handle complex operations gracefully', async () => {
    // Set up a decision for graceful handling test
    const decision = {
      actionId: 'core:wait',
      targets: {},
      speech: 'Handling complex scenario gracefully.',
      thoughts: 'Testing module resilience.',
    };

    // Test that module handles graceful operations in complex scenarios
    // Note: Test module provides robust error handling and operational resilience

    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: decision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:wait']: {
          success: true,
          validatedAction: {
            actionId: 'core:wait',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    // Execute turn to verify module handles operations gracefully
    const turnResult = await testEnv.executeAITurn('ai-actor');

    // Verify module completed successfully even in complex scenarios
    expect(turnResult.success).toBe(true);
    expect(turnResult.aiDecision.actionId).toBe('core:wait');
  });

  /**
   * Test: Validation-Only Mode
   *
   * Validates that test module can validate actions without executing them
   * for testing and preview scenarios.
   *
   * TEST MODULE PATTERN: Built-in validation-only mode support
   */
  test('should support validation-only mode for action testing', async () => {
    // Set up decision for validation testing
    const decision = {
      actionId: 'core:wait',
      targets: {},
      speech: 'This should only be validated.',
      thoughts: 'Testing validation without execution.',
    };

    testEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: decision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:wait']: {
          success: true,
          validatedAction: {
            actionId: 'core:wait',
            actorId: 'ai-actor',
            targets: {},
          },
        },
      },
    });

    // Execute in validation-only mode using module option
    const turnResult = await testEnv.facades.turnExecutionFacade.executeAITurn(
      'ai-actor',
      { situation: 'validation test' },
      { validateOnly: true }
    );

    // Verify validation succeeded but no execution occurred
    expect(turnResult.success).toBe(true);
    expect(turnResult.aiDecision.actionId).toBe('core:wait');
    expect(turnResult.validation.success).toBe(true);
    expect(turnResult.execution).toBeFalsy(); // Should be null or undefined in validate-only mode
    expect(turnResult.duration).toBeGreaterThanOrEqual(0);
  });

  /**
   * Test: Multiple Actors Integration
   *
   * Validates that test module can handle multiple actors efficiently
   * as mentioned in the report for concurrent testing.
   *
   * TEST MODULE PATTERN: Simplified multi-actor coordination
   */
  test('should handle multiple actors taking turns efficiently', async () => {
    // Create test environment with multiple actors
    const multiActorEnv = await TestModuleBuilder.forTurnExecution()
      .withMockLLM({ strategy: 'tool-calling' })
      .withTestActors([
        { id: 'ai-actor', name: 'AI Character' },
        { id: 'player-actor', name: 'Player Character' },
      ])
      .withWorld({ name: 'Multi-Actor World' })
      .build();

    // Set up decisions for both actors
    const aiDecision = {
      actionId: 'core:look',
      targets: {},
      speech: 'AI actor observes the environment.',
      thoughts: 'Learning about the world.',
    };

    const playerDecision = {
      actionId: 'core:wait',
      targets: {},
      speech: 'Player waits patiently.',
      thoughts: 'Taking time to think.',
    };

    multiActorEnv.facades.turnExecutionFacade.setupMocks({
      aiResponses: {
        ['ai-actor']: aiDecision,
        ['player-actor']: playerDecision,
      },
      actionResults: {
        ['ai-actor']: [
          { actionId: 'core:look', name: 'Look Around', available: true },
        ],
        ['player-actor']: [
          { actionId: 'core:wait', name: 'Wait', available: true },
        ],
      },
      validationResults: {
        ['ai-actor:core:look']: {
          success: true,
          validatedAction: {
            actionId: 'core:look',
            actorId: 'ai-actor',
            targets: {},
          },
        },
        ['player-actor:core:wait']: {
          success: true,
          validatedAction: {
            actionId: 'core:wait',
            actorId: 'player-actor',
            targets: {},
          },
        },
      },
    });

    // Execute turns for both actors
    const aiResult = await multiActorEnv.executeAITurn('ai-actor');
    const playerResult = await multiActorEnv.executeAITurn('player-actor');

    // Verify both actors executed successfully
    expect(aiResult.success).toBe(true);
    expect(aiResult.aiDecision.actionId).toBe('core:look');
    expect(playerResult.success).toBe(true);
    expect(playerResult.aiDecision.actionId).toBe('core:wait');

    // Verify performance for multi-actor scenarios
    expect(aiResult.duration).toBeGreaterThanOrEqual(0);
    expect(playerResult.duration).toBeGreaterThanOrEqual(0);
    expect(aiResult.duration + playerResult.duration).toBeLessThan(200); // Combined execution under 200ms

    // Cleanup multi-actor environment
    await multiActorEnv.cleanup();
  });
});
